{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relatório Diário de Qualidade - RDQ\n",
    "\n",
    "#### Perfomance das tags de qualidade do papel produzido pela máquina em questão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tzlocal import get_localzone\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#df de dados do PTP-AF\n",
    "\n",
    "path_specs = #NOME DO DIRETÓRIO DAS ESPECIFICAÇÕES\n",
    "\n",
    "df_af = pd.read_excel(path_specs + '/dir',sheet_name='dir_specs')\n",
    "\n",
    "df_af = df_af.iloc[:,2:11].drop(columns = ['Peso'])\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#lista de tags\n",
    "tags = ['B5OPT_015_AVG','B5OPT_061_AVG','B5OPT_090_AVG','B5OPT_091_AVG','B5OPT_104_AVG','B5OPT_117_AVG',\n",
    "        'B5OPT_158_AVG','B5OPT_171_AVG','B5OPT_175_AVG','B5OPT_176_AVG',\n",
    "        'B5OPT_183_AVG','B5OPT_187_AVG','B5OPT_188_AVG','B5P11BW1NPROLA',\n",
    "        'B5P11CG1NPROLA','B5FI1555PV','P1CWP1VESDFV','P1CCP1VESDFV','B5OPT_GRADE_SPEC','QUEBRAS_MB5_HST']\n",
    "\n",
    "#descrição das tags\n",
    "descript = ['GRAMATURA LAB','ESTOURO FELTRO','SUJIDADE FELTRO','SUJIDADE TELA','ALVURA ISO FELTRO (C2)',\n",
    "            'FLUORESCÊNCIA FELTRO','UMIDADE LAB','DENSIDADE','DESFIBRAMENTO','ABSORÇÃO ESPECÍFICA','ESPESSURA LAB',\n",
    "            'CAPACIDADE ESPECÍFICA','ENERGIA DESFIBRAMENTO','GRAMATURA SCANNER',\n",
    "            'ESPESSURA SCANNER','UMIDADE SCANNER','DESVIO TRANSVERSAL DE GRAMATURA',\n",
    "            'DESVIO TRANSVERSAL DE ESPESSURA']\n",
    "\n",
    "#categoria das tags\n",
    "cat = ['EXTERNO','EXTERNO','EXTERNO','EXTERNO','EXTERNO','INTERNO','EXTERNO','EXTERNO','INTERNO','HISTÓRICO',\n",
    "       'EXTERNO','HISTÓRICO','INTERNO','SCANNER','SCANNER','SCANNER','SCANNER','SCANNER']\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#conectando e extraindo dados a serem analisados\n",
    "import osisoft.pidevclub.piwebapi\n",
    "\n",
    "user= #USER PARA ACESSO\n",
    "pw = #PASSWORD DO USER\n",
    "\n",
    "from osisoft.pidevclub.piwebapi.pi_web_api_client import PIWebApiClient  \n",
    "client = PIWebApiClient('https://NAME_DIR/piwebapi', False, user, pw, False) #INCLUIR NAME_DIR\n",
    "path = 'NAME_DIR_LOCAL' #INCLUIR NAME_DIR_LOCAL\n",
    "\n",
    "paths = []\n",
    "\n",
    "for tag in tags:\n",
    "    paths.append(path + tag)\n",
    "\n",
    "#puxar dados do dia anterior a cada 1 min\n",
    "df1 = client.data.get_multiple_interpolated_values(paths, start_time = '*-1440m', end_time = '*',interval = '1m')\n",
    "print('OK!')\n",
    "\n",
    "df_aux = [df1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#pré-processamento: selecionar apenas as colunas de valores e uma coluna de Timestamp, renomear colunas dos df's\n",
    "numbers = np.arange(1,(len(tags)+1),1)\n",
    "value = 'Value'\n",
    "list_values = ['Timestamp1']\n",
    "for number in numbers:\n",
    "    list_values.append(value + str(number))\n",
    "\n",
    "tags.insert(0,'TIMESTAMP')\n",
    "\n",
    "list_df = []\n",
    "\n",
    "for df in df_aux:   \n",
    "\n",
    "    df = df.loc[1:,list_values]\n",
    "    \n",
    "    df = df.rename(columns = dict(zip(list_values,tags)))\n",
    "    \n",
    "    list_df.append(df)\n",
    "    \n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#transformar em um df só\n",
    "for index in range(len(list_df)):\n",
    "    \n",
    "    if index == 0:\n",
    "        df = list_df[index]\n",
    "    else:\n",
    "        df = df.append(list_df[index],ignore_index = True)\n",
    "        \n",
    "df = df.reset_index().drop(columns = ['index'])\n",
    "\n",
    "#excluindo períodos de quebra (influência nas tags de scanner)\n",
    "df = df[df['QUEBRAS_MB5_HST'] == 0]\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para excluir bad data\n",
    "def fix_bad_data(df, bad_data=[\"Bad Data\",\"No Data\",\"Bad\",\"I/O Timeout\",\"Calc Failed\",\n",
    "                               \"Arc Off-line\",\"Comm Fail\",\"Configure\",\"Intf Shut\",\n",
    "                               {'Name': 'I/O Timeout', 'Value': 246, 'IsSystem': True},\n",
    "                               {'Name': 'Calc Failed', 'Value': 249, 'IsSystem': True},\n",
    "                               {'Name': 'Bad', 'Value': 307, 'IsSystem': True},\n",
    "                               {'Name': 'Intf Shut', 'Value': 311, 'IsSystem': True}]): #erros possíveis no sistema\n",
    "    \n",
    "    df = df.apply(lambda x: x.replace(bad_data, np.nan), axis=0)\n",
    "    \n",
    "    df = df.dropna(axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#vetor timestamp\n",
    "aux_tsp = df[['TIMESTAMP']]\n",
    "\n",
    "#separar diferentes df's de acordo com as diferentes os diferentes produtos - papel - produzidos\n",
    "prods = df['B5OPT_GRADE_SPEC'].unique()\n",
    "\n",
    "df_prod = []\n",
    "\n",
    "for prod in prods:\n",
    "    \n",
    "    aux = df[df['B5OPT_GRADE_SPEC'] == prod]\n",
    "    aux = aux.drop(columns = ['TIMESTAMP','B5OPT_GRADE_SPEC','QUEBRAS_MB5_HST'])\n",
    "    aux = fix_bad_data(aux)\n",
    "    aux = aux.describe().T.drop(columns = ['count']).iloc[:,:2]\n",
    "    \n",
    "    df_prod.append(aux)\n",
    "    \n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#intervalo de cálculo\n",
    "aux_tsp = pd.to_datetime(aux_tsp['TIMESTAMP'],format = '%Y-%m-%d').to_list()\n",
    "tsp = []\n",
    "for dt in aux_tsp:\n",
    "    tsp.append(dt.astimezone(tz = 'America/Sao_Paulo'))\n",
    "    \n",
    "#day_i = str(tsp[0].day) + '/' + str(tsp[0].month) + '/' + str(tsp[0].year)\n",
    "day_f = str(tsp[-1].day) + '/' + str(tsp[-1].month) + '/' + str(tsp[-1].year)\n",
    "#interval = day_i + ' - ' + day_f\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#lendo csv antigo e captando semana antiga\n",
    "try:\n",
    "    old_df = pd.read_csv('RDQ_MB5.csv', sep = ';', decimal = ',', encoding = 'latin-1')\n",
    "\n",
    "    old_df = old_df.iloc[:,1:]\n",
    "\n",
    "    old_sem = sorted(list(old_df.Semana.unique()))[-1]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#descobrindo a semana\n",
    "df_date = pd.read_excel('data_semana.xlsx') #ARQUIVO COM NÚMEROS DAS SEMANAS\n",
    "df_date = df_date[(df_date.Dia_ini <= tsp[-1].date()) & (df_date.Dia_fin >= tsp[-1].date())]\n",
    "sem = df_date.Semana.values[0]\n",
    "\n",
    "if sem == 1:\n",
    "    os.remove('RDQ_MB5.csv') #ARQUIVO DE PERFORMANCE É ANUAL\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#excluindo tags de grade e quebra\n",
    "#lista de tags - tags com ambos os limites, tags sem limites inferior e tags sem limites superiores\n",
    "\n",
    "tags = ['B5OPT_015_AVG','B5OPT_061_AVG','B5OPT_090_AVG','B5OPT_091_AVG','B5OPT_104_AVG','B5OPT_117_AVG',\n",
    "        'B5OPT_158_AVG','B5OPT_171_AVG','B5OPT_175_AVG','B5OPT_176_AVG','B5OPT_183_AVG','B5OPT_187_AVG',\n",
    "        'B5OPT_188_AVG','B5P11BW1NPROLA','B5P11CG1NPROLA','B5FI1555PV','P1CWP1VESDFV','P1CCP1VESDFV']\n",
    "\n",
    "tags_sem_LI = ['B5OPT_117_AVG','B5OPT_176_AVG','B5OPT_188_AVG']\n",
    "\n",
    "tags_sem_LS = ['B5OPT_104_AVG','B5OPT_175_AVG','B5OPT_183_AVG','B5OPT_187_AVG','B5P11CG1NPROLA']\n",
    "\n",
    "#conseguir valores do arquivo PTP-AF\n",
    "for num in range(len(prods)):\n",
    "    \n",
    "    aux_desc = []\n",
    "    aux_cat = []\n",
    "    aux_unit = []\n",
    "    aux_LI = []\n",
    "    aux_LS = []\n",
    "    aux_grade = []\n",
    "    aux_dt = []\n",
    "    aux_sem = []\n",
    "\n",
    "    for index in range(len(tags)):\n",
    "        \n",
    "        if tags[index] == 'B5P11BW1NPROLA': #gramatura scanner - puxar spec da tag do lab    \n",
    "            aux_df = df_af[(df_af['Tag'] == 'B5OPT_015_AVG') & (df_af['Grade'] == prods[num])]\n",
    "        elif tags[index] == 'B5P11CG1NPROLA': #espessura scanner - puxar spec da tag do lab    \n",
    "            aux_df = df_af[(df_af['Tag'] == 'B5OPT_183_AVG') & (df_af['Grade'] == prods[num])]\n",
    "        elif tags[index] == 'B5FI1555PV': #umidade scanner - puxar spec da tag do lab    \n",
    "            aux_df = df_af[(df_af['Tag'] == 'B5OPT_158_AVG') & (df_af['Grade'] == prods[num])]\n",
    "            \n",
    "        else:   \n",
    "            aux_df = df_af[(df_af['Tag'] == tags[index]) & (df_af['Grade'] == prods[num])]\n",
    "            \n",
    "        #Descrição\n",
    "        aux_desc.append(descript[index])\n",
    "        \n",
    "        #Categoria\n",
    "        aux_cat.append(cat[index])\n",
    "        \n",
    "        #UM (unidade de medida)\n",
    "        try:\n",
    "            aux_unit.append(aux_df['UNIT'].to_list()[0])\n",
    "        except:\n",
    "            aux_unit.append('Unknown')\n",
    "        \n",
    "        #LI (limite inferior)\n",
    "        if tags[index] in tags_sem_LI:\n",
    "            aux_LI.append(np.nan)\n",
    "        else:\n",
    "            try:\n",
    "                aux_LI.append(aux_df['LimInf'].to_list()[0])\n",
    "            except:\n",
    "                aux_LI.append(np.nan)\n",
    "        \n",
    "        #LS (limite superior)\n",
    "        if tags[index] in tags_sem_LS:\n",
    "            aux_LS.append(np.nan)\n",
    "        else:\n",
    "            try:\n",
    "                aux_LS.append(aux_df['LimSup'].to_list()[0])\n",
    "            except:\n",
    "                aux_LS.append(np.nan)\n",
    "        \n",
    "        #Grade, Dia do Cálculo, Semana do Cálculo\n",
    "        aux_grade.append(prods[num])\n",
    "        aux_dt.append(day_f)\n",
    "        aux_sem.append(sem)\n",
    "    \n",
    "    df_prod[num]['Descrição'] = aux_desc\n",
    "    df_prod[num]['Categoria'] = aux_cat\n",
    "    df_prod[num]['UM'] = aux_unit\n",
    "    df_prod[num]['LimInf'] = aux_LI\n",
    "    df_prod[num]['LimSup'] = aux_LS\n",
    "    df_prod[num]['Grade'] = aux_grade\n",
    "    df_prod[num]['Data'] = aux_dt\n",
    "    df_prod[num]['Semana'] = aux_sem\n",
    "    \n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#cálculo de Cp e Cpk\n",
    "#lista de tags\n",
    "\n",
    "for num in range(len(df_prod)):\n",
    "    \n",
    "    aux_cp = []\n",
    "    aux_cpk = []\n",
    "    \n",
    "    for index in range(len(tags)):\n",
    "\n",
    "        df_aux = df_prod[num].loc[tags[index],:]\n",
    "\n",
    "        if tags[index] in tags_sem_LI: #tags sem LI - não tem Cp\n",
    "            cpk = (df_aux['LimSup'] - df_aux['mean'])/(3*df_aux['std'])\n",
    "            aux_cp.append(np.nan)\n",
    "            aux_cpk.append(cpk)\n",
    "        elif tags[index] in tags_sem_LS: #tags sem LS - não tem Cp\n",
    "            cpk = (df_aux['mean'] - df_aux['LimInf'])/(3*df_aux['std'])\n",
    "            aux_cp.append(np.nan)\n",
    "            aux_cpk.append(cpk)\n",
    "        else:\n",
    "            cp = (df_aux['LimSup'] - df_aux['LimInf'])/(6*df_aux['std'])\n",
    "            aux_cp.append(cp)\n",
    "\n",
    "            cpk1 = (df_aux['LimSup'] - df_aux['mean'])/(3*df_aux['std'])\n",
    "            cpk2 = (df_aux['mean'] - df_aux['LimInf'])/(3*df_aux['std'])\n",
    "            if cpk1 < cpk2:\n",
    "                aux_cpk.append(cpk1)\n",
    "            else:\n",
    "                aux_cpk.append(cpk2)\n",
    "\n",
    "    df_prod[num]['Cp'] = aux_cp\n",
    "    df_prod[num]['Cpk'] = aux_cpk\n",
    "    \n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#retoques finais\n",
    "for num in range(len(df_prod)):\n",
    "    \n",
    "    df_prod[num] = df_prod[num][['Descrição','UM','mean','std','LimInf','LimSup',\n",
    "                                 'Cp','Cpk','Categoria','Grade','Data','Semana']]\n",
    "    \n",
    "    df_prod[num] = df_prod[num].rename(columns = {'mean': 'Média', 'std': 'DesvPad'})\n",
    "    \n",
    "    df_prod[num] = df_prod[num].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    df_prod[num] = df_prod[num].reset_index().rename(columns = {'index':'Tags'})\n",
    "    \n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#juntando os df's novos com o csv velho\n",
    "try:\n",
    "    new_df = old_df.copy()\n",
    "\n",
    "    for df_specprod in df_prod:\n",
    "        new_df = pd.concat([new_df, df_specprod], ignore_index = True)\n",
    "        \n",
    "except:\n",
    "    new_df = df_prod[0].copy()\n",
    "    \n",
    "    for index in range(len(df_prod)):\n",
    "        if index == 0:\n",
    "            pass\n",
    "        else:\n",
    "            new_df = pd.concat([new_df, df_prod[index]], ignore_index = True)\n",
    "            \n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIM!\n"
     ]
    }
   ],
   "source": [
    "#alterando separador de coluna e de decimal\n",
    "new_df.to_csv('RDQ_MB5.csv', decimal = ',', sep = ';', encoding = 'latin-1')\n",
    "\n",
    "print('FIM!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
